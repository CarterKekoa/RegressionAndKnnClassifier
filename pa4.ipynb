{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'jupyter_utils' from '/home/pa4-CarterKekoa/jupyter_utils.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "\n",
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import jupyter_utils\n",
    "importlib.reload(jupyter_utils)"
   ]
  },
  {
   "source": [
    "# PA4 Simple Classifiers\n",
    "## Part 2: Auto Dataset Classification  \n",
    "Write a Jupyter Notebook (pa4.ipynb) that uses your mysklearn package to build simple classifiers for the \"pre-processed\" automobile dataset (auto-data-removed-NA.txt) you created for PA2. In the Notebook, describe the steps, log any assumptions and/or issues you had in doing the steps, and provide insights on the step results. All re-usable utility functions should be separate from your Notebook in an appropriate module.\n",
    "\n",
    "### Step 1 Train/Test Sets: Random Instances and Linear Regression  \n",
    "Create a classifier that predicts mpg values using (least squares) linear regression based on vehicle weight. Your classifier should take one or more instances, compute the predicted MPG values, and then map these to the DOE classification/ranking (given in PA3) for each corresponding instance. Test your classifier by selecting 5 random instances from the dataset, predict their corresponding mpg ranking, and then show their actual mpg ranking as follows:\n",
    "\n",
    "* Changes:\n",
    "    * I had an issue with using fit() on two different lists, one has nested list values and one was a list of values. I had to add to the fit() function to account for this issue. \n",
    "* Data:\n",
    "    * The predictions were correct 4/5 times consistantly which is pretty good! However the cars that there were less instances of were not usually guessed correctly.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================================\nSTEP 1: Linear Regression MPG Classifier\n===========================================\ninstance: [20.0, 8.0, 262.0, 110.0, 3221.0, 13.5, 75.0, 1.0, 'chevrolet monza 2+2', 3953.0]\nclass: 5 actual:  5\ninstance: [14.0, 8.0, 454.0, 220.0, 4354.0, 9.0, 70.0, 1.0, 'chevrolet impala', 3132.0]\nclass: 1 actual:  2\ninstance: [22.0, 6.0, 250.0, 105.0, 3353.0, 14.5, 76.0, 1.0, 'chevrolet nova', 3413.0]\nclass: 4 actual:  5\ninstance: [32.8, 4.0, 78.0, 52.0, 1985.0, 19.4, 78.0, 3.0, 'mazda glc deluxe', 3145.0]\nclass: 7 actual:  8\ninstance: [20.5, 6.0, 231.0, 105.0, 3425.0, 16.9, 77.0, 1.0, 'buick skylark', 3865.0]\nclass: 4 actual:  5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Get the file data\n",
    "fname = os.path.join(\"input_data\", \"auto-data-removed-NA.txt\")\n",
    "auto_data = MyPyTable().load_from_file(fname)\n",
    "\n",
    "# Grab the car weights column and store in a list\n",
    "weight = auto_data.get_column('weight')\n",
    "weight = [[val] for val in weight]\n",
    "# split the data\n",
    "x_train_split, x_test_split, y_train_split, y_test_split = myevaluation.train_test_split(weight, auto_data.get_column('mpg'), shuffle=True)\n",
    "\n",
    "# get the regression line information\n",
    "myline = MySimpleLinearRegressor()\n",
    "myline.fit(x_train_split,y_train_split)\n",
    "\n",
    "# randomize the data for 5 rows\n",
    "rand_rows = jupyter_utils.get_rand_rows(auto_data, 5)\n",
    "print(\"===========================================\")\n",
    "print(\"STEP 1: Linear Regression MPG Classifier\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "# for row in the random row list\n",
    "for row in rand_rows:\n",
    "    print('instance:', row)\n",
    "    print('class:', jupyter_utils.get_rating(myline.predict([[row[4]]])[0]), 'actual: ',juputils.get_rating(row[0]))"
   ]
  },
  {
   "source": [
    "### Step 2 Train/Test Sets: Random Instances and kNN  \n",
    "Create a nearest neighbor classifier for mpg that uses the number of cylinders, weight, and acceleration attributes to predict mpg for k = 5. Be sure to normalize the three attribute values and also use the Euclidean distance metric. Similar to Step 1, test your classifier by selecting 5 random instances from the dataset, predict their corresponding mpg ranking, and then show their actual mpg ranking:\n",
    "* Changes:\n",
    "    * A scale function needed to be made to scale the data to be between [0, 1]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================================\nSTEP 2: k=5 Nearest Neighbor MPG Classifier\n===========================================\ninstance: [16.0, 6.0, 258.0, 110.0, 3632.0, 18.0, 74.0, 1.0, 'amc matador', 3699.0]\nclass: 5 actual:  3\ninstance: [21.0, 4.0, 140.0, 72.0, 2401.0, 19.5, 73.0, 1.0, 'chevrolet vega', 2192.0]\nclass: 6 actual:  5\ninstance: [19.0, 3.0, 70.0, 97.0, 2330.0, 13.5, 72.0, 3.0, 'mazda rx2 coupe', 2290.0]\nclass: 1 actual:  4\ninstance: [22.0, 6.0, 250.0, 105.0, 3353.0, 14.5, 76.0, 1.0, 'chevrolet nova', 3413.0]\nclass: 4 actual:  5\ninstance: [27.2, 4.0, 141.0, 71.0, 3190.0, 24.8, 79.0, 2.0, 'peugeot 504', 8040.0]\nclass: 1 actual:  7\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"STEP 2: k=5 Nearest Neighbor MPG Classifier\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "mknc = MyKNeighborsClassifier(5) # set the amount of neighbors to 5\n",
    "\n",
    "# Get the 3 column data sets\n",
    "weight = auto_data.get_column('weight') \n",
    "cylinders = auto_data.get_column('cylinders')\n",
    "acceleration = auto_data.get_column('acceleration')\n",
    "\n",
    "# store each columns data in x_vals and scale the data\n",
    "x_vals = [[weight[i], cylinders[i],acceleration[i]] for i in range(len(weight))]\n",
    "scaled_x, blank = myutils.scale(x_vals, [[]])\n",
    "\n",
    "# train and split the test list\n",
    "x_train_split, x_test_split, y_train_split, y_test_split = myevaluation.train_test_split(scaled_x, auto_data.get_column('mpg'), shuffle=True)\n",
    "\n",
    "mknc.fit(x_train_split, auto_data.get_column('mpg')) # fit the data\n",
    "rand_rows = jupyter_utils.get_rand_rows(auto_data, 5) # randomize 5 rows\n",
    "\n",
    "# for each row in the random list of 5\n",
    "for row in rand_rows:\n",
    "    print('instance:', row)\n",
    "    scaled_vals, scaled_test = myutils.scale(x_vals, [[row[4],row[1],row[5]]])\n",
    "    print('class:', jupyter_utils.get_rating(mknc.predict(scaled_test)[0]), 'actual: ', juputils.get_rating(row[0]))"
   ]
  },
  {
   "source": [
    "### Step 3 Train/Test Sets: Random Sub-sampling\n",
    "Compute the predictive accuracy and error rate of the two classifiers using random sub-sampling with k = 10. Your output should look something like this (where the ??'s should be replaced by actual values):\n",
    "* This one was a bit difficult but didnt require me to create any new funcitons to pull it off.\n",
    "* Data:\n",
    "    * The accuracy seemed to run a bit low which means that the algorithm was not regularly correct in its predictions. This also means the error rate was high. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================================\nSTEP 3: Predictive Accuracy\n===========================================\nRandom Subsample (k=10, 2:1 Train/Test)\nLinear Regression: accuracy =  0.38372093023255816 error rate = 0.6162790697674418\nK Nearest Neighbors: accuracy =  0.2441860465116279 error rate = 0.7558139534883721\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"STEP 3: Predictive Accuracy\")\n",
    "print(\"===========================================\")\n",
    "print(\"Random Subsample (k=10, 2:1 Train/Test)\")\n",
    "\n",
    "# grab the auto data\n",
    "auto_data = MyPyTable().load_from_file(fname)\n",
    "\n",
    "# get the column data \n",
    "weight = auto_data.get_column('weight')\n",
    "weight = [[val] for val in weight]\n",
    "\n",
    "# split the data\n",
    "x_train_split, x_test_split, y_train_split, y_test_split = myevaluation.train_test_split(weight, auto_data.get_column('mpg'), shuffle=True)\n",
    "\n",
    "# train the regression line\n",
    "myline = MySimpleLinearRegressor()\n",
    "myline.fit(x_train_split,y_train_split)\n",
    "\n",
    "# predict using the regression line\n",
    "predicted = myline.predict(x_test_split)\n",
    "predicted = [jupyter_utils.get_rating(val) for val in predicted]\n",
    "expected = [jupyter_utils.get_rating(val) for val in y_test_split]  # store the expected values\n",
    "\n",
    "correct = 0\n",
    "# for each index value in the predicted list\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == expected[i]:\n",
    "        correct += 1\n",
    "print('Linear Regression: accuracy = ', correct/len(predicted), 'error rate =', 1-correct/len(predicted))\n",
    "\n",
    "# grab the colums individual\n",
    "weight = auto_data.get_column('weight')\n",
    "cylinders = auto_data.get_column('cylinders')\n",
    "acceleration = auto_data.get_column('acceleration')\n",
    "\n",
    "# store the colum values in the x_vals\n",
    "x_vals = [[weight[i], cylinders[i], acceleration[i]] for i in range(len(weight))]\n",
    "scaled_x, scaled_test = myutils.scale(x_vals, [[]]) # scale them\n",
    "\n",
    "# split the data\n",
    "x_train_split, x_test_split, y_train_split, y_test_split = myevaluation.train_test_split(scaled_x, auto_data.get_column('mpg'), shuffle=True)\n",
    "\n",
    "mknc = MyKNeighborsClassifier(10) # set the amount of neighbors to 10\n",
    "# fit the data\n",
    "mknc.fit(x_train_split, y_train_split)\n",
    "\n",
    "# predict using the regression line\n",
    "predicted = mknc.predict(x_test_split)\n",
    "predicted = [jupyter_utils.get_rating(val) for val in predicted]\n",
    "expected = [jupyter_utils.get_rating(val) for val in y_test_split]\n",
    "\n",
    "correct = 0\n",
    "# for each index value in the predicted list\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] == expected[i]:\n",
    "        correct += 1\n",
    "print('K Nearest Neighbors: accuracy = ', correct/len(predicted), 'error rate =', 1-correct/len(predicted))"
   ]
  },
  {
   "source": [
    "### Step 4 Train/Test Sets: Cross Validation\n",
    "Compute the predictive accuracy and error rate of the two classifiers using separate training and test sets. You should use mpg rankings for both k-fold cross validation and stratified k-fold cross validation with k = 10. Your output should look something like this (where the ??'s should be replaced by actual values):\n",
    "* Corrections:\n",
    "    * I needed to make a function that counted the predictions that were correct. \n",
    "* Data:\n",
    "    * The predictions for the cross validation were actually pretty high menaing it was able to predict rather well.\n",
    "    * However the stratified k fold was not regularly very accurate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================================\n",
      "STEP 4: Predictive Accuracy\n",
      "===========================================\n",
      "10-Fold Cross Validation\n",
      "Linear Regression: accuracy = 0.8185328185328186 error rate = 0.18146718146718144\n",
      "K Nearest Neighbors: accuracy = 0.528957528957529 error rate = 0.471042471042471\n",
      "\n",
      "Stratified 10-Fold Cross Validation\n",
      "Linear Regression: accuracy = 0.3166023166023166 error rate = 0.6833976833976834\n",
      "K Nearest Neighbors: accuracy = 0.14671814671814673 error rate = 0.8532818532818532\n"
     ]
    }
   ],
   "source": [
    "# Reload the libraries\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "importlib.reload(mysklearn.myutils)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "print(\"===========================================\")\n",
    "print(\"STEP 4: Predictive Accuracy\")\n",
    "print(\"===========================================\")\n",
    "print(\"10-Fold Cross Validation\")\n",
    "\n",
    "# get the column data \n",
    "weight = [[val] for val in auto_data.get_column('weight')]\n",
    "train_folds, test_folds = myevaluation.kfold_cross_validation(weight, 10)\n",
    "\n",
    "# grab the mpg column\n",
    "mpg = [jupyter_utils.get_rating(val) for val in auto_data.get_column('mpg')]\n",
    "\n",
    "# fold the column data\n",
    "X_train, y_train, X_test, y_test = myutils.get_from_folds(weight, mpg, train_folds, test_folds)\n",
    "\n",
    "# fit the line to a regression\n",
    "myline = MySimpleLinearRegressor()\n",
    "myline.fit(X_train,y_train)\n",
    "\n",
    "# predict  the data\n",
    "prediction = [round(val) for val in myline.predict(X_test)]\n",
    "actual_linear = y_test\n",
    "\n",
    "# count the amount of correct predictions\n",
    "count = jupyter_utils.correct_count(prediction, y_test)\n",
    "print('Linear Regression: accuracy =', count/len(prediction), 'error rate =', 1 - count/len(prediction))\n",
    "\n",
    "# grab the colums individual\n",
    "weight = auto_data.get_column('weight')\n",
    "cylinders = auto_data.get_column('cylinders')\n",
    "acceleration = auto_data.get_column('acceleration')\n",
    "\n",
    "# store the colum values in the x_vals\n",
    "x_vals = [[weight[i], cylinders[i],acceleration[i]] for i in range(len(weight))]\n",
    "scaled_x, _ = myutils.scale(x_vals, [[]])\n",
    "\n",
    "# make the folds\n",
    "train_folds, test_folds = myevaluation.kfold_cross_validation(scaled_x, 10)\n",
    "y = [jupyter_utils.get_rating(val) for val in auto_data.get_column('mpg')]\n",
    "\n",
    "# get the train and test lists\n",
    "X_train, y_train, X_test, y_test = myutils.get_from_folds(scaled_x, y, train_folds, test_folds)\n",
    "\n",
    "mknc = MyKNeighborsClassifier(10) # set the amount of neighbors to 10\n",
    "mknc.fit(X_train,y_train)\n",
    "\n",
    "# predict the neighbors in test\n",
    "predicted_neighbors = mknc.predict(X_test)\n",
    "actual_neighbors = y_test\n",
    "count = jupyter_utils.correct_count(predicted_neighbors, y_test) # count the amount of correct neighbors predicted\n",
    "\n",
    "print('K Nearest Neighbors: accuracy =', count/len(predicted_neighbors), 'error rate =', 1 - count/len(predicted_neighbors))\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# grab the weigbt column\n",
    "weight = [[val] for val in auto_data.get_column('weight')]\n",
    "y = [jupyter_utils.get_rating(val) for val in auto_data.get_column('mpg')]\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(weight, y, 10)\n",
    "\n",
    "# Get the ratings for each of the mpg values\n",
    "ratings = [jupyter_utils.get_rating(val) for val in auto_data.get_column('mpg')]\n",
    "\n",
    "# grab the folds\n",
    "X_train, y_train, X_test, y_test = myutils.get_from_folds(weight, ratings, train_folds, test_folds)\n",
    "\n",
    "# fit the Regression line\n",
    "myline = MySimpleLinearRegressor()\n",
    "myline.fit(X_train,y_train)\n",
    "\n",
    "# make the predictions\n",
    "prediction_stratified = [round(val) for val in myline.predict(X_test)]\n",
    "actual_linear_stratified = y_test\n",
    "\n",
    "# count the amount of correct predictions\n",
    "count = jupyter_utils.correct_count(predicted_linear_stratified, y_test)\n",
    "\n",
    "print('\\nStratified 10-Fold Cross Validation\\nLinear Regression: accuracy =', count/len(predicted_linear_stratified), 'error rate =', 1 - count/len(predicted_linear_stratified))\n",
    "\n",
    "# grab the colums individual\n",
    "weight = auto_data.get_column('weight')\n",
    "cylinders = auto_data.get_column('cylinders')\n",
    "acceleration = auto_data.get_column('acceleration')\n",
    "\n",
    "# store the colum values in the x_vals\n",
    "x_vals = [[weight[i], cylinders[i],acceleration[i]] for i in range(len(weight))]\n",
    "scaled_x, blank = myutils.scale(x_vals, [[]])\n",
    "\n",
    "# Get the ratings for each of the mpg values\n",
    "rating = [jupyter_utils.get_rating(val) for val in auto_data.get_column('mpg')]\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(scaled_x, rating, 10)\n",
    "\n",
    "# Grabt he folds\n",
    "X_train, y_train, X_test, y_test = myutils.get_from_folds(scaled_x, rating, train_folds, test_folds)\n",
    "\n",
    "# set the amount of neighbors to 10\n",
    "mknc = MyKNeighborsClassifier(10)\n",
    "mknc.fit(X_train,y_train)\n",
    "\n",
    "# predict the neighbors\n",
    "predicted_neighbors_stratified = mknc.predict(X_test)\n",
    "actual_neighbors_stratified = y_test\n",
    "\n",
    "# count the amount of correct predictions\n",
    "count = jupyter_utils.correct_count(predicted_neighbors_stratified, y_test)\n",
    "\n",
    "print('K Nearest Neighbors: accuracy =', count/len(predicted_neighbors_stratified), 'error rate =', 1 - count/len(predicted_neighbors_stratified))"
   ]
  },
  {
   "source": [
    "### Step 5 Confusion Matrices  \n",
    "Create confusion matrices for each classifier based on the stratified 10-fold cross validation results. You can use the tabulate package to display your confusion matrices (it is also okay to format the table manually). Here is an example:\n",
    "* Data:\n",
    "    * It seems the matrix was not able to guess the correct label very often.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n===========================================\nSTEP 5: Confusion Matrices\n===========================================\n\nLinear Regression (Stratified 10-fold Cross Validation Results)\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n    1    8   10    8    0    1    0    0    0    0     0       28              28.57\n    2    2    9    4    0    1    0    0    0    0     0       18              50\n    3    1   14   12    8    1    0    0    0    0     0       39              30.77\n    4    0    1   11   25   11    2    1    0    0     0       55              45.45\n    5    0    0    1   12   19   15    0    0    0     0       52              36.54\n    6    0    0    0    1    6   21    6    0    0     0       40              52.5\n    7    0    0    0    1    0    8   18    0    0     0       34              52.94\n    8    0    0    0    0    0    1   16    1    0     0       26               3.85\n    9    0    0    0    0    0    0    2    0    0     0       11               0\n   10    0    0    0    0    0    0    0    0    0     0       10               0\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n\nK Neighbors (Stratified 10-fold Cross Validation Results)\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n  MPG    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n    1   13    9    4    2    0    0    0    0    0     0       29              44.83\n    2    7    2    5    2    0    0    0    0    0     0       18              11.11\n    3    5    6   12    9    4    0    0    0    0     0       39              30.77\n    4    1    0    8   24   16    2    0    0    0     0       55              43.64\n    5    0    0    3   16   18    6    3    1    0     0       52              34.62\n    6    0    0    0    3   10   13    4    4    0     0       40              32.5\n    7    0    0    0    1    2    7    8    7    2     0       34              23.53\n    8    0    0    0    0    0    5    4    9    0     0       26              34.62\n    9    0    0    0    0    0    1    1    0    0     0       11               0\n   10    0    0    0    0    0    0    0    0    0     0       10               0\n=====  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(jupyter_utils)\n",
    "print('\\n===========================================\\n\\\n",
    "STEP 5: Confusion Matrices\\n\\\n",
    "===========================================\\n')\n",
    "matrix = myevaluation.confusion_matrix(actual_linear_stratified, predicted_linear_stratified, [0,1,2,3,4,5,6,7,8,9,10])\n",
    "table_header = ['MPG', 1,2, 3 ,4, 5, 6, 7, 8, 9, 10, 'Total', 'Recognition (%)']\n",
    "jupyter_utils.add_conf_stats(matrix)\n",
    "\n",
    "print('Linear Regression (Stratified 10-fold Cross Validation Results)')\n",
    "jupyter_utils.print_tabulate(matrix, table_header)\n",
    "\n",
    "matrix = myevaluation.confusion_matrix(actual_neighbors_stratified, predicted_neighbors_stratified, [0,1,2,3,4,5,6,7,8,9,10])\n",
    "jupyter_utils.add_conf_stats(matrix)\n",
    "\n",
    "print('\\nK Neighbors (Stratified 10-fold Cross Validation Results)')\n",
    "jupyter_utils.print_tabulate(matrix, table_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}